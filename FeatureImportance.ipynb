{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNm2Fg3Ail/zHnDXpIAWMNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majidiali1/machine-learning/blob/main/FeatureImportance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Selection**"
      ],
      "metadata": {
        "id": "2LtdHVTAyw8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Principle Component Analysis**"
      ],
      "metadata": {
        "id": "-4jznS72y1IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'feature1': [1, 4, 6, 8, 10],\n",
        "    'feature2': [1, 4, 6, 8, 10],\n",
        "    'feature3': [1, 16, 36, 64, 100],\n",
        "    'feature4': [10, 40, 60, 80, 10],\n",
        "    'feature5': [100, 400, 600, 800, 100],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# # Standardizing the features\n",
        "# scaler = StandardScaler()\n",
        "# df = pd.DataFrame(scaler.fit_transform(df))\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "qj7WNbuO-Hqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ae8d14-d5a3-466b-eb18-5809ff5fd201"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   feature1  feature2  feature3  feature4  feature5\n",
            "0         1         1         1        10       100\n",
            "1         4         4        16        40       400\n",
            "2         6         6        36        60       600\n",
            "3         8         8        64        80       800\n",
            "4        10        10       100        10       100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Applying PCA\n",
        "pca = PCA(n_components=2)  # None means all components are kept\n",
        "pca.fit(df_scaled)\n",
        "X_pca = pca.fit_transform(df)\n",
        "\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "feature_importance_matrix = pd.DataFrame(pca.components_, columns=df.columns, index=[f'PC{i+1}' for i in range(len(pca.components_))])\n"
      ],
      "metadata": {
        "id": "aQ9qIUAfy5j0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(22, 7))\n",
        "\n",
        "# Scree Plot\n",
        "axes[0].bar(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_)\n",
        "axes[0].set_title('Scree Plot')\n",
        "axes[0].set_xlabel('Principal Component')\n",
        "axes[0].set_ylabel('Variance Explained')\n",
        "axes[0].set_xticks(range(1, pca.n_components_ + 1))\n",
        "\n",
        "# PCA Component Makeup\n",
        "feature_importance_matrix.abs().plot(kind='bar', ax=axes[1])\n",
        "axes[1].set_title('PCA Component Makeup')\n",
        "axes[1].set_ylabel('Absolute Coefficient Value')\n",
        "axes[1].set_xlabel('Principal Components')\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()  # Adjust layout to not overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rfFCu1521vsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Correlation Matrix**"
      ],
      "metadata": {
        "id": "Ot1l2v5K99RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `df` is your DataFrame\n",
        "corr_matrix = df.corr()\n",
        "print(corr_matrix)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yKpv5wJx-BAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mutual Information Regression**"
      ],
      "metadata": {
        "id": "c3SdVgVqClMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to calculate MI between each pair of features\n",
        "def calculate_mutual_information(df):\n",
        "    mi_matrix = pd.DataFrame(index=df.columns, columns=df.columns, data=0.0)\n",
        "\n",
        "    for col in df.columns:\n",
        "        for other_col in df.columns:\n",
        "            if col != other_col:\n",
        "                mi = mutual_info_regression(df[[col]], df[other_col], discrete_features=False)\n",
        "                mi_matrix.loc[col, other_col] = mi[0]\n",
        "\n",
        "    return mi_matrix\n",
        "\n",
        "# Calculate MI for each feature pair\n",
        "mi_matrix = calculate_mutual_information(df)\n",
        "\n",
        "# Plotting the mutual information matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(mi_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Mutual Information between Feature Pairs\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6tEh2Sh-CpNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detect relationship formula between features using PolynomialFeatures**"
      ],
      "metadata": {
        "id": "oViq3GeBXSPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample DataFrame creation for demonstration\n",
        "data = {\n",
        "    'feature1': [1, 4, 6, 8, 10],\n",
        "    'feature2': [1, 4, 6, 8, 10],\n",
        "    'feature3': [1, 16, 36, 64, 100],\n",
        "    'feature4': [10, 40, 60, 80, 10],\n",
        "    'feature5': [100, 400, 600, 800, 100],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Function to fit polynomial regression, construct a relationship formula, ignoring 0.00 coefficients\n",
        "def fit_and_describe_relationship(df, feature_x, feature_y, degree=2):\n",
        "    x = df[[feature_x]]\n",
        "    y = df[feature_y]\n",
        "\n",
        "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "    x_poly = poly.fit_transform(x)\n",
        "\n",
        "    model = LinearRegression().fit(x_poly, y)\n",
        "\n",
        "    # Constructing formula, ignoring near-zero coefficients\n",
        "    terms = []\n",
        "    if abs(model.intercept_) > 1e-4:  # Adjust threshold as needed\n",
        "        terms.append(f\"{model.intercept_:.2f}\")\n",
        "    for i, coef in enumerate(model.coef_):\n",
        "        if abs(coef) > 1e-4:  # Ignore near-zero coefficients\n",
        "            term = f\"({coef:.2f})\"\n",
        "            if i > 0:\n",
        "                term += f\" * {feature_x}^{i+1}\"\n",
        "            else:\n",
        "                term += f\" * {feature_x}\"\n",
        "            terms.append(term)\n",
        "\n",
        "    formula = \" + \".join(terms) if terms else \"0\"\n",
        "    return f\"{feature_y} = {formula}\"\n",
        "\n",
        "# Analyzing relationships for all pairs of features\n",
        "relationships = []\n",
        "for feature_x, feature_y in combinations(df.columns, 2):\n",
        "    formula_xy = fit_and_describe_relationship(df, feature_x, feature_y, degree=2)\n",
        "    relationships.append((feature_x, feature_y, formula_xy))\n",
        "    formula_yx = fit_and_describe_relationship(df, feature_y, feature_x, degree=2)\n",
        "    relationships.append((feature_y, feature_x, formula_yx))\n",
        "\n",
        "# Displaying the relationships, ignoring effectively zero coefficients\n",
        "for rel in relationships:\n",
        "    print(f\"{rel[0]} vs {rel[1]} => {rel[2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7XeOTcUPzx",
        "outputId": "80ced1ea-f344-4ea1-8175-8bf7083e4617"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature1 vs feature2 => feature2 = (1.00) * feature1\n",
            "feature2 vs feature1 => feature1 = (1.00) * feature2\n",
            "feature1 vs feature3 => feature3 = (1.00) * feature1^2\n",
            "feature3 vs feature1 => feature1 = 1.18 + (0.16) * feature3 + (-0.00) * feature3^2\n",
            "feature1 vs feature4 => feature4 = -23.73 + (29.83) * feature1 + (-2.52) * feature1^2\n",
            "feature4 vs feature1 => feature1 = 6.55 + (-0.13) * feature4 + (0.00) * feature4^2\n",
            "feature1 vs feature5 => feature5 = -237.26 + (298.30) * feature1 + (-25.18) * feature1^2\n",
            "feature5 vs feature1 => feature1 = 6.55 + (-0.01) * feature5\n",
            "feature2 vs feature3 => feature3 = (1.00) * feature2^2\n",
            "feature3 vs feature2 => feature2 = 1.18 + (0.16) * feature3 + (-0.00) * feature3^2\n",
            "feature2 vs feature4 => feature4 = -23.73 + (29.83) * feature2 + (-2.52) * feature2^2\n",
            "feature4 vs feature2 => feature2 = 6.55 + (-0.13) * feature4 + (0.00) * feature4^2\n",
            "feature2 vs feature5 => feature5 = -237.26 + (298.30) * feature2 + (-25.18) * feature2^2\n",
            "feature5 vs feature2 => feature2 = 6.55 + (-0.01) * feature5\n",
            "feature3 vs feature4 => feature4 = 4.04 + (2.75) * feature3 + (-0.03) * feature3^2\n",
            "feature4 vs feature3 => feature3 = 72.10 + (-2.51) * feature4 + (0.03) * feature4^2\n",
            "feature3 vs feature5 => feature5 = 40.39 + (27.50) * feature3 + (-0.27) * feature3^2\n",
            "feature5 vs feature3 => feature3 = 72.10 + (-0.25) * feature5 + (0.00) * feature5^2\n",
            "feature4 vs feature5 => feature5 = (10.00) * feature4\n",
            "feature5 vs feature4 => feature4 = (0.10) * feature5\n"
          ]
        }
      ]
    }
  ]
}